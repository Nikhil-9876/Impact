<p align="center">
  <img src="https://img.shields.io/badge/AI-Audio%20Detector-blueviolet?style=for-the-badge&logo=soundcloud&logoColor=white" alt="AI Audio Detector"/>
  <img src="https://img.shields.io/badge/WavLM-Ensemble-orange?style=for-the-badge&logo=pytorch&logoColor=white" alt="WavLM"/>
  <img src="https://img.shields.io/badge/FastAPI-REST%20API-009688?style=for-the-badge&logo=fastapi&logoColor=white" alt="FastAPI"/>
  <img src="https://img.shields.io/badge/Docker-Deployable-2496ED?style=for-the-badge&logo=docker&logoColor=white" alt="Docker"/>
</p>

# ğŸ›¡ï¸ Impact â€” AI Voice Deepfake Detector

> **Detect AI-generated speech from real human voices across multiple Indian languages using a WavLM-based ensemble deep learning model.**

Impact is an end-to-end system that classifies audio as **AI-generated** or **genuine human speech** with high confidence. Built for multilingual Indian language support, it combines Microsoft's WavLM foundation model with dual classification heads (AASIST + OC-Softmax) in a production-ready FastAPI service.

---

## ğŸ“ Architecture Diagram

<!-- Eraser Diagram Embed â€” Replace the src URL below with your Eraser diagram link -->
<!-- To create your diagram: https://app.eraser.io â†’ Create a new diagram â†’ Export as image or use embed link -->

![Architecture Diagram](https://app.eraser.io/workspace/YOUR_WORKSPACE_ID)

<!-- If using Eraser embed (interactive): -->
<!-- <a href="https://app.eraser.io/workspace/YOUR_WORKSPACE_ID" target="_blank"><img src="https://app.eraser.io/workspace/YOUR_WORKSPACE_ID/preview" alt="Architecture Diagram" /></a> -->

<!-- Alternative: If you export the diagram as a PNG and add it to the repo: -->
<!-- ![Architecture Diagram](./assets/architecture-diagram.png) -->

---

## âœ¨ Key Features

| Feature | Description |
|---------|-------------|
| ğŸ§  **WavLM Backbone** | Leverages Microsoft WavLM-base as a frozen feature extractor for robust audio representations |
| ğŸ¯ **Dual-Head Ensemble** | AASIST (attention-based) + OC-Softmax heads with weighted ensemble (60/40) |
| ğŸŒ **Multilingual** | Supports **Tamil, English, Hindi, Malayalam, Telugu** |
| ğŸ”Š **Sliding Window** | Processes audio up to 60s using overlapping 5-second windows (50% overlap) |
| ğŸ›¡ï¸ **Audio Validation** | Rejects silent, clipped, or non-speech audio before inference |
| ğŸ” **API Key Auth** | Secure access via `x-api-key` header |
| ğŸ³ **Docker Ready** | Single-command deployment with Docker |
| ğŸ“Š **Quality Checks** | RMS energy, zero-crossing rate, spectral centroid, and clipping validation |

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CLIENT REQUEST                           â”‚
â”‚            (Audio File / Base64 MP3 + Language + API Key)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FastAPI Server                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  /api/detect  â”‚  â”‚  /api/voice  â”‚  â”‚  /api/encode-base64   â”‚  â”‚
â”‚  â”‚  -from-file   â”‚  â”‚  -detection  â”‚  â”‚                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                 â”‚                                      â”‚
â”‚         â–¼                 â–¼                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚  â”‚     Audio Preprocessing         â”‚                             â”‚
â”‚  â”‚  â€¢ Load & Resample (16kHz)      â”‚                             â”‚
â”‚  â”‚  â€¢ Quality Validation           â”‚                             â”‚
â”‚  â”‚  â€¢ Bandpass Filter (80-7800 Hz) â”‚                             â”‚
â”‚  â”‚  â€¢ Peak Normalization           â”‚                             â”‚
â”‚  â”‚  â€¢ Sliding Window (5s, 50% hop) â”‚                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                 â–¼                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                             â”‚
â”‚  â”‚   WavLM Feature Extraction      â”‚                             â”‚
â”‚  â”‚   (microsoft/wavlm-base)        â”‚                             â”‚
â”‚  â”‚   768-dim hidden states          â”‚                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚
â”‚                 â–¼                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚   AASIST Head       â”‚   OC-Softmax Head  â”‚                    â”‚
â”‚  â”‚   (Attention + MLP) â”‚   (LayerNorm + MLP) â”‚                   â”‚
â”‚  â”‚   Weight: 0.6       â”‚   Weight: 0.4       â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                       â–¼                                          â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚            â”‚  Ensemble Average   â”‚                               â”‚
â”‚            â”‚  across all windows â”‚                               â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                      â–¼                                           â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚            â”‚   Classification    â”‚                               â”‚
â”‚            â”‚  AI_GENERATED or    â”‚                               â”‚
â”‚            â”‚  HUMAN + Confidence â”‚                               â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- FFmpeg (for MP3 support)
- CUDA GPU (recommended, CPU supported)

### 1. Clone & Install

```bash
git clone https://github.com/YOUR_USERNAME/Impact.git
cd Impact
pip install -r requirements.txt
```

### 2. Set API Key

```bash
export API_KEY="your-secret-api-key"
```

### 3. Add Model Weights

Place your trained model files in the project root:
- `best_model.pt` â€” Trained WavLM + AASIST + OC-Softmax checkpoint
- `optimal_threshold.txt` â€” Detection threshold (optional, defaults to 0.5)

### 4. Run the API

```bash
python api.py
```

The API will be live at **http://localhost:8000** â€” interactive docs at **http://localhost:8000/docs**

---

## ğŸ³ Docker Deployment

```bash
# Build
docker build -t impact-ai-detector .

# Run
docker run -p 7860:7860 -e API_KEY="your-secret-api-key" impact-ai-detector
```

---

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/` | API info & available endpoints |
| `GET` | `/health` | Health check & model status |
| `POST` | `/api/detect-from-file` | **Upload audio file directly** (recommended) |
| `POST` | `/api/voice-detection` | Detect from base64-encoded MP3 |
| `POST` | `/api/encode-to-base64` | Convert audio file to base64 |

### Example: File Upload (Recommended)

```bash
curl -X POST "http://localhost:8000/api/detect-from-file" \
  -H "x-api-key: your-secret-api-key" \
  -F "file=@sample_audio.mp3" \
  -F "language=English"
```

### Example Response

```json
{
  "status": "success",
  "classification": "AI_GENERATED",
  "confidenceScore": 0.92
}
```

### Example: Python Client

```python
import requests

response = requests.post(
    "http://localhost:8000/api/detect-from-file",
    headers={"x-api-key": "your-secret-api-key"},
    files={"file": open("audio.mp3", "rb")},
    data={"language": "Tamil"}
)
print(response.json())
```

---

## ğŸ§ª Model Training

The training pipeline is in [`Modelf.ipynb`](Modelf.ipynb) and runs on Kaggle with GPU acceleration.

### Training Data

| Class | Languages | Source |
|-------|-----------|--------|
| **Human** | English, Hindi, Tamil, Telugu, Malayalam | AI4Bharat dataset |
| **AI** | English, Hindi, Tamil, Telugu, Malayalam | AI-generated speech samples |

### Training Pipeline

1. **Data Loading** â€” Multi-path loader supporting flat/nested folder structures
2. **Augmentation** â€” Speed perturbation, gain variation, noise injection, codec simulation, random EQ, clipping
3. **Feature Extraction** â€” WavLM-base with top-2 layer fine-tuning
4. **Classification** â€” Dual-head training (AASIST + OC-Softmax) with label smoothing
5. **Optimization** â€” AdamW optimizer, gradient clipping, early stopping on AUC
6. **Threshold Tuning** â€” ROC-based optimal threshold selection

### Key Training Configs

| Parameter | Value |
|-----------|-------|
| Sample Rate | 16,000 Hz |
| Window Duration | 5.0 seconds |
| Batch Size | 32 |
| Learning Rate | 2e-4 |
| Epochs | 10 |
| Dropout | 0.3 |
| Label Smoothing | 0.05 |
| WavLM Unfrozen Layers | Top 2 |

---

## ğŸ“ Project Structure

```
Impact/
â”œâ”€â”€ api.py                 # FastAPI production server (inference API)
â”œâ”€â”€ Modelf.ipynb           # Training notebook (Kaggle)
â”œâ”€â”€ keepalive_app.py       # HuggingFace Space keep-alive service
â”œâ”€â”€ test_file_upload.py    # API testing script
â”œâ”€â”€ Dockerfile             # Docker container config
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ best_model.pt          # Trained model weights (not in repo)
â”œâ”€â”€ optimal_threshold.txt  # Detection threshold (not in repo)
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ README_API.md          # Detailed API documentation
â””â”€â”€ README_KEEPALIVE.md    # Keep-alive service docs
```

---

## ğŸ”§ Tech Stack

| Component | Technology |
|-----------|-----------|
| **ML Framework** | PyTorch, Transformers (HuggingFace) |
| **Audio Processing** | torchaudio, librosa, soundfile |
| **Foundation Model** | Microsoft WavLM-base |
| **API Framework** | FastAPI + Uvicorn |
| **Containerization** | Docker |
| **Deployment** | HuggingFace Spaces / Any cloud |
| **Training Platform** | Kaggle (GPU P100/T4) |

---

## ğŸŒ Deployment on HuggingFace Spaces

The project includes a **keep-alive service** ([`keepalive_app.py`](keepalive_app.py)) that pings your HuggingFace Space every 24 hours to prevent sleep mode.

```bash
# Set your HF Space URL
export HF_SPACE_URL="https://your-username-your-space.hf.space"

# Run the keep-alive service
python keepalive_app.py
```

---

## ğŸ¤ Team

Built for hackathon submission by **Team Impact**.

---

## ğŸ“„ License

This project is open source and available under the [MIT License](LICENSE).

---

<p align="center">
  <b>Built with â¤ï¸ for safer AI â€” detecting deepfakes, one audio at a time.</b>
</p>